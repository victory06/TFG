% !TeX root = ../libro.tex
% !TeX encoding = utf8

\setchapterpreamble[c][0.75\linewidth]{%
	\sffamily
  Definiremos los modelos utilizados en el trabajo. 
	\par\bigskip
}
\chapter{Aprendizaje automático}\label{ch:machine-learning}
El aprendizaje automático es una aplicación de la inteligencia artificial que provee al sistema de la habilidad para aprender automáticamente y mejorar con la experiencia sin ser explícitamente programado para ello (Arthur Samuel, 1959). Hace uso de los algoritmos de aprendizaje que son algoritmos que estiman una dependencia desconocida entre los datos de entrada y de salida de un sistema desde unas muestras conocidas. Una vez esta dependencia ha sido estimada, se puede usar para predecir las futuras salidas del sistema a partir de los valores de entrada conocidos.\\
Hay tres tipos de aprendizajes:
\begin{itemize}
  \item Aprendizaje \textbf{supervisado}: Es el tipo de aprendizaje más utilizado. Se aplica a datos \textbf{etiquetados}. Tiene como objetivo aprender la función desconocida que asigna los datos con las etiquetas minimizando una función de error. lo usaremos para nuestro conjunto de datos, pues es etiquetado.
  \item Aprendizaje \textbf{no supervisado}: Se usa para los datos no etiquetados y se pretende buscar patrones o relaciones entre los datos. Un ejemplo típico de este tipo de aprendizaje es el de \textbf{agrupamiento} o \textit{clustering} que busca agrupar los datos según algún patrón o relación.
  \item Aprendizaje \textbf{por refuerzo}: En vez de ser etiquetado, da solo una indicación de si la predicción es correcta o no mediante alguna recompensa o penalización en función de las acciones que haga.
\end{itemize}
\cite{jordan2015machine}\\
Un primer ejemplo y esquema de aprendizaje automático sería el siguiente, supongamos que hay un banco que recive miles de solicitudes para una tarjeta de crédito y quiere automatizar el proceso. No se conoce ninguna fórmula para aceptar o denegar una tarjeta pero se dispone de gran cantidad de datos de los aplicantes: información personal, sueldo, prestamos pendientes y más información relacionada al crédito, así que se usan estos datos para encontrar una fórmula adecuada.\\
Así, se tiene la entrada \textbf{x} (información del cliente), la función desconocida ideal para llevar a cabo la decisión $f:X \rightarrow Y$, donde $X$ es el espacio de la entrada (conjunto de las posibles entradas de \textbf{x}), e $Y$ es el espacio de la salida (conjunto de todas las posibles salidas, en este caso una decisión de sí o no). Se denotará al set de datos por $D$, con ejemplos de entrada-salida $(x_{1},y_{1}),...,(x_{N},y_{N})$ donde $y_{n}=f(x_{n})$ para $n=1,...,N$. Los ejemplos se suelen llamar observaciones. Por último, hay un algoritmo de aprendizaje que aproxima $g:X \rightarrow Y$ a $f$.  El algoritmo elige $g$ de entre un conjunto de funciones candidatas, $H$, como por ejemplo el conjunto de todas las funciones lineales.\\
El banco usará la función $g$ para hacer la decisión puesto que la $f$ ideal no la tiene así que el algoritmo elige la $g$ que mejor aproxima $f$ en un conjunto de \textit{entrenamiento} o \textit{training} de anteriores clientes. \cite{abu2012learning}\\
La siguiente figura ilusta esquemáticamente el problema de aprendizaje:
\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\textwidth]{Problema_aprendizaje_basico}
  \caption{Esquema básico de aprendizaje.}
  \label{fig:k-nn-example}
\end{figure}

Para este trabajo, $X=\mathbb{R}^{d}$, siendo $\mathbb{R}^{d}$ un espacio euclídeo d-dimensional, con las coordenadas descritas en el \autoref{ch:base-datos} siendo cada columna una coordenada, $Y=\lbrace 0,2 \rbrace$ una decisión binaria de si el individuo es sano o afectado (o padre de afectado para el estudio con controles).
\section{Descripción de los modelos utilizados}\label{st:modelos-utilizados}
El problema que se pretende resolver en este trabajo consiste en una predicción de etiquetas, es decir, al uso del aprendizaje supervisado para resolverlo. Dentro del aprendizaje supervisado encontramos varios modelos de gran potencia predictiva como los que describiremos en esta sección.
\subsection{k-Nearest Neighbors}\label{sst:k-nn}
El modelo k-Nearest Neighbours (k-NN) es uno de los modelos más intuitivos y transparentes y se aleja un poco de la idea de aproximar una función ideal para tomar la decisión de clasificación. La idea básica se muestra en la \autoref{fig:k-nn-example}. Se clasificará el vecino desconocido con la clase de los vecinos más cercanos a él, y si hay de varios tipos como en la figura, se puede resolver por simple mayoría o por votación ponderada por distancia, que veremos más adelante. Así que en k-NN se pueden diferenciar dos etapas: primero determinar los vecinos más cercanos y segundo, determinar la clase usando esos vecinos. \cite{padraiddelany2007k}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.4\textwidth]{k-nn-example}
  \caption{Ejemplo de 4-NN.}
  \label{fig:k-nn-example}
\end{figure}
\begin{center}
\cite{peterson2009k}
\end{center}

\subsubsection{Métrica}
Sea $X$=$\lbrace x_{1},...,x_{n} \rbrace$ donde $n=\mid X \mid$ un conjunto de entrenamiento, con x representando las instancias. Las instancias están descritas por un conjunto de variables $F$. Cada instancia de entrenamiento está etiquetada con una etiqueta de clase $y_{i} \in Y$, es decir, la función de etiquetado establece una aplicación biyectiva entre $X$ e $Y$. El objetivo es clasificar un ejemplo desconocido \textbf{$q$}.\cite{padraiddelany2007k}\\
Para cada $x_{i} \in X$ calculamos la distancia como la distancia de :
\[ MD_{p}(\textbf{q},x_{i})= (\sum_{f \in F}  \vert q_{f} - x_{if} \vert ^{p})^{1/p} \quad \cite{inproceedings} \] 
Para p=1 la distancia de Minkowski es la llamada distancia Manhattan, para p=2, la Euclídea y para p=$\infty$ la de Chebychev. Sus expresiones son las que siguen \cite{inproceedings}:
\[ d^{2}(q,x_{i})= (q-x_{i})(q-x_{i})' \quad Euclídea \]
\[ d(q,x_{i})=\sum_{f \in F}  \vert q_{f} - x_{if} \vert \quad  Manhattan \]
\[ d(q,x_{i})=max_{f \in F} \lbrace \vert q_{f} - x_{if} \vert \rbrace \quad Chebychev \]

\subsubsection{Votación}
La votación consiste en establecer un criterio para asignar a $q$ una de las etiquetas de $Y$. Esto puede hacerse asignando la etiqueta que tengan la mayoría de vecinos más cercanos a $q$ o también puede establecerse una función de votación. La más usual es establecer la votación en función de la inversa de la distancia entre $q$ y sus vecinos. 
\[ Vote(y_{i}) = \sum^{k}_{c=1} \frac{1}{(d(q,x_{c})^{p}} 1(y_{j},y_{c}) \]
Donde $1(y_{j},y_{c})$ devuelve 1 si las etiquetas son iguales y 0 en caso contrario. En la función, $p$ se suele establecer a 1 pero se puede aumentar o disminuir para cambiar la influencia que tiene la distancia en el voto. \cite{padraiddelany2007k}

\subsection{Regresión Logística}\label{st:reglog}
Para la regresión logística sí que se busca aproximar esa función que se hablaba al principio del capítulo. Para ello, se especifica el conjunto de hipótesis $H$ mediante una forma funcional que todas las hipótesis $h \in H$  comparten. Esta fórmula funcional $h(x)$ se elige dando diferentes \textit{pesos} a cada coordenada de x que reflejan la importancia que esa coordenada tiene en la decisión tomada. Este primer modelo de $H$ se da en el \textit{perceptron}, si llamamos $w$ a los pesos, se diría que el individuo es afectado si \[ \sum_{i=1}^{d}w_{i}x_{i} > umbral \]
\[ \textnormal{y no afectado si } \sum_{i=1}^{d}w_{i}x_{i} < umbral \]
Pudiendo escribir la fórmula más compacta como:
\[ h(x)=sign((\sum_{i=1}^{d}w_{i}x_{i})+b) \]
donde $x_{1},...,x_{d}$ son los componentes del vector x. Si da 1 el individuo es afectado y si da -1 es sano. En el primer caso se le asigna la etiqueta 2 y en el segundo caso la 0, entrando así en el recorrido de nuestro problema. Los pesos y el umbral están determinados por el sesgo $b$ de forma que el individuo está afectado si $\sum_{i=1}^{d} w_{i}x_{i} > -b$. Para simplificar la notación se va a escribir $b$ como el peso $w_{0}=b$ y juntarlo con los demás pesos en un solo vector columna \textbf{w}$=[w_{0},w_{1},...,w_{d}]^{T}$ y también modificamos el vector x como x=[$x_{0},x_{1},...,x_{n}$], donde se le añade la coordenada $x_{0}$ establecida a 1. El espacio de entrada, el dominio, será así
\[ X = \lbrace 1 \rbrace \times \mathbb{R} = \lbrace [x_{0},...,x_{d}]^{T} \vert x_{0}=1, x_{i} \in \mathbb{R} \textnormal{ } \forall i \in \lbrace 1,...,d \rbrace \rbrace\]
y se puede escribir \textbf{$w^{T}x$}=$\sum_{i=1}^{d} w_{i}x_{i}$ y la ecuación de la hipótesis $h(x)$ quedaría:
\[ h(x) = sign(w^{T}x) \]
\cite{abu2012learning}\\
La regresión logística se separa de la clasificación lineal en que la decisión que toma no es binaria sino que tiene como salida una \textbf{probabilidad}, un valor entre 0 y 1. La clasificación lineal usa un umbral basado en $w^{T}x$, $h(x) = sign(w^{T}x)$ mientras que la regresión lineal no usa ningún umbral $h(x) =w^{T}x$. En la regresión logística se busca algo intermedio que se consigue con la función \textit{logística} $\theta(s)=\frac{e^{s}}{1+e^{s}}$ cuyo valor está entre 0 y 1, quedando \[ h(x)=\theta(w^{T}x) \] cuyo valor se interpreta como la probabilidad de que ocurra un suceso binario. Se está tratando de aprender la probabilidad de que el individuo esté afectado por el trastorno y eso depende de la entrada x. La función objetivo es por tanto $f(x)= \mathbb{P} [y=1 \vert x]$ pero los datos no dan el valor de $f$ de forma explícita sino observaciones de ésta (individuos que ya se sabe que están afectados). Por tanto, los datos están generados por una distribución objetivo $P(y \vert x)$,
\[P(y \vert x)=\spalignsys{
f(x) \textnormal{      para }  y=1;
1-f(x) \textnormal{   para }  y=-1}\]
así que para aprenderlo se necesita una medida de \textbf{error} que indique cómo de parecida es la $h$ a la función objetivo $f$ en términos de las etiquetas de las observaciones.\cite{abu2012learning}\\
Por tanto se tiene que el conjunto de muestras $X=\lbrace x_{1},...,x_{N} \rbrace$ es una muestra aleatoria simple pues los individuos son tomados de forma independiente y están idénticamente distribuidos.\\
El error en este modelo se basa en la idea de cómo es de "probable" que se consiga la salida $y$ de la entrada $x$ si la distribución objetivo $P(y \vert x)$ estuviera definida por nuestra hipótesis $h(x)$. Esto sería:
\[P(y \vert x)=\spalignsys{
h(x) \textnormal{      para }  y=1;
1-h(x) \textnormal{   para }  y=-1}\]
Sustituyendo $h(x)$ por su valor $\theta(yw^{T}x)$ y usando que $1-\theta(s)=\theta(-s)$, probado a continuación, queda \[ P(y \vert x)=\theta(yw^{T}x) \]
\begin{proposicion}La función logística $\theta: \mathbb{R} \rightarrow [0,1] \textnormal{, } \theta(s)=\frac{e^{s}}{1+e^{s}}$ tiene la propiedad simétrica: \[1-\theta(s)=\theta(-s) \textnormal{ } \forall s \in \mathbb{R} \]
\end{proposicion}
\begin{proof}
Se toma $s \in \mathbb{R}$ y se tiene que $1-\theta(s)=1-\frac{e^{s}}{1+e^{s}}$, multiplicando numerador y denominador por $e^{-s}$ en la fracción queda $1-\frac{1}{1+e^{-s}}$, realizando la resta se tiene $\frac{1+e^{-s}-1}{1+e^{-s}}$ y simplificando queda $\frac{e^{-s}}{1+e^{-s}}=\theta(-s)$, como se quería demostrar.
\end{proof}
Las observaciones $(x_{1},y_{1}),...,(x_{N},y_{N})$ son tomadas independientemente así que la probabilidad de obtener todas las salidas $y_{n}$ en los datos desde la correspondiente muestra $x_{n}$ sería el producto \[ \prod_{n=1}^{N}P(y_{n} \vert x_{n}) \].
Método de la máxima verosimilitud en la \autoref{st:emv}.

\endinput











